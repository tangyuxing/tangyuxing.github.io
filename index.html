<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <style>html {scroll-behavior: smooth;}</style>

  <title>Yuxing Tang</title>
  
  <meta name="author" content="Yuxing Tang">
  <meta name="descripction" content="Yuxing Tang is a Senior Research Scientist at PAII Inc. USA.">
  <meta name="keywords" content="Yuxing Tang, PAII, Medical imaging, Computer Aided Diagnosis, Deep Learning, Computer Science">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=0.36, maximum-scale=5.0, minimum-scale=0.36"> -->
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.jpg">

  <script src="scripts/functions.js"></script>
</head>

<body data-gr-c-s-loaded="true">
<table width="880" border="0" align="center" cellspacing="0" cellpadding="20"><tbody><tr><td>
<!-- <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px"> -->

<!-- title -->

<p align="center">
    <pageheading>Yuxing Tang</pageheading><br>
    <b>Email</b> : <font id="email" style="display:inline;">tangyuxing87 [AT] gmail [DOT] com</font>
</p>

<!-- avatar and bio -->

<table width="88%" align="center" border="0" cellspacing="0" cellpadding="30"><tbody><tr>
    <td width="30%" valign="center">
        <img src="images/yuxingtang.jpg" width="100%" style="border-radius:20px">
        <p align="center">
        <!-- TODO:: update cv path  <02-10-19, YL> -->
        <!-- TODO:: add linked in  <06-10-19, YL> -->
        | <a href="pdfs/resume.pdf">CV</a> | <a href="https://scholar.google.com/citations?user=QtYC2MIAAAAJ&hl=en">Google Scholar</a> | <!--<a href="https://github.com/">Github</a> | -->
        </p>
    </td>

    <td width="70%" valign="center" align="justify">
        <p> Yuxing Tang is currently a senior research scientist at <strong>PAII Inc.</strong>, USA. Before that, he was a postdoctoral visiting fellow at the National Institutes of Health (<strong>NIH</strong>). He received the <strong>Ph.D. </strong> degree in <strong> Computer Science</strong> at Ecole Centrale de Lyon, France in 2016. He completed his bachelor and master degree in Beijing Jiaotong University, China. His research focuses on computer vision, deep learning, and their applications in medical imaging, computer-aided diagnosis, and weakly supervised object/lesion detection.</p>
    </td>
</tr></tbody></table>

<!-- news -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
    <tbody><tr><td>
        <sectionheading>&nbsp;&nbsp;News</sectionheading>
            <ul>
                <li> <b>[July 2021]</b> Two scientific abstracts including one oral presentation are accepted at <a href='https://www.rsna.org/annual-meeting' target="_blank"> RSNA 2021</a>.</li>
                <li> <b>[June 2021]</b> Our work on multi-view mass detection/segmentation in mammograms has been accepted for publication in <a href='https://www.journals.elsevier.com/medical-image-analysis/' target="_blank"> Medical Image Analysis</a>. Paper will be available soon.</li>
                <li> <b>[May 2021]</b> Two co-authored papers are accepted at <a href='https://www.miccai2021.org/' target="_blank"> MICCAI 2021</a>. Congratulations Yanbo and Zhenjie!</li>
                <li> <b>[Mar. 2021]</b> A first-authored paper on <a href='https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Leveraging_Large-Scale_Weakly_Labeled_Data_for_Semi-Supervised_Mass_Detection_in_CVPR_2021_paper.html' target="_blank"> semi-supervised mass detection in mammograms</a> is accepted at <a href='http://cvpr2021.thecvf.com/' target="_blank"> CVPR 2021.</li>
                <a href="javascript:toggleblock(&#39;old_news&#39;)" id="element1" onClick="javascript:changeText(1)">---Show more---</a>
                <div id="old_news" style="display: none;">
                <li> <b>[Dec. 2020]</b> Our work on universal lesion detection in CT has been accepted for publication in <a href='https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=42' target="_blank"> IEEE TMI</a>. Congratulations to Ke!
                <li> <b>[Nov. 2020]</b> Yet another work on few-shot learning in chest X-rays has been accepted for publication in <a href='https://www.journals.elsevier.com/medical-image-analysis/' target="_blank"> Medical Image Analysis</a>. Congratulations to Angshuman!
                <li> <b>[Oct. 2020]</b> Our work on disease decomposition in chest X-rays has been accepted for publication in <a href='https://www.journals.elsevier.com/medical-image-analysis/' target="_blank"> Medical Image Analysis</a>. Congratulations to Youbao!
                <li> <b>[June 2020]</b> Left the NIH and will be joining <a href='http://www.paii-labs.com/'> PAII Inc.</a> as a senior research scientist.</li>
                <li> <b>[June 2020]</b> Received the Outstanding Reviewer Award at <a href='http://cvpr2020.thecvf.com/reviewer-acknowledgements' target="_blank"> CVPR 2020</a>.</li>
            </div></div></ul>
    </td></tr></tbody>
</table>

<!-- publication -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tbody><tr><td><sectionheading>&nbsp;&nbsp;Selected Publications <a href='https://scholar.google.com/citations?user=QtYC2MIAAAAJ&hl=en' target="_blank"> (Full list)</a> 
    <a href="#journal_pub">| Journals |</a>  <a href="#conf_pub"> Conferences |</a>  </sectionheading></td></tr></tbody>
  <tbody><tr><td><heading>&nbsp;&nbsp;<p id="journal_pub"><li>Journals</li></p></heading></td></tr></tbody> 
</table>

<!-- yang2021momminetv2 -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="mommi_stop()" onmouseover="mommi_start()">
    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="mommi_image" style="opacity: 0;">
                <img src="images/media_mommiv2_res.gif" ,="" width="100%">
            </div>
            <div class="image_constant" id="mommi_constant" style="opacity: 1;">
                <img src="images/media_mommiv2.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function mommi_start() {
                document.getElementById('mommi_constant').style.opacity = "0";
                document.getElementById('mommi_image').style.opacity = "1";
            }

            function mommi_stop() {
                document.getElementById('mommi_image').style.opacity = "0";
                document.getElementById('mommi_constant').style.opacity = "1";
            }
            mommi_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <!-- <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520302036?dgcid=rss_sd_all" id="tang2021disentangled"> -->
                <heading>MommiNet-v2: Mammographic multi-view mass identification networks</heading>
            </a><br>
            Zhicheng Yang, Zhenjie Cao, Yanbo Zhang, <b>Yuxing Tang</b>, Xiaohui Lin, Rushan Ouyang, Mingxiang Wu, Mei Han, Jing Xiao, Lingyun Huang, Shibin Wu, Peng Chang, Jie Ma<br>
            <i>Medical Image Analysis (<b>MedIA</b>), 2021. </i><br>
            | To appear soon. |
          <!-- | <a href="data/yang2021momminetv2.bib">BibTeX</a> | -->
        </p>
        <p>
            MommiNet-v2 aggregates information from the high-resolution representations of all mammographic views and incorporates the malignancy information from both biopsy and BI-RADS categories.
        </p>
    </td>

</tr>
</tbody></table>

<!-- tang2021disentangled -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="cxr_decomp_stop()" onmouseover="cxr_decomp_start()">
    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="decomp_image" style="opacity: 0;">
                <img src="images/mia_cxr_dec_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="decomp_constant" style="opacity: 1;">
                <img src="images/mia_cxr_dec.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function cxr_decomp_start() {
                document.getElementById('decomp_constant').style.opacity = "0";
                document.getElementById('decomp_image').style.opacity = "1";
            }

            function cxr_decomp_stop() {
                document.getElementById('decomp_image').style.opacity = "0";
                document.getElementById('decomp_constant').style.opacity = "1";
            }
            cxr_decomp_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520302036?dgcid=rss_sd_all" id="tang2021disentangled">
                <heading>A disentangled generative model for disease decomposition in chest X-rays via normal image synthesis</heading>
            </a><br>
            Youbao Tang, <b>Yuxing Tang</b>, Yingying Zhu, Jing Xiao, Ronald M. Summers<br>
            <i>Medical Image Analysis (<b>MedIA</b>), 2021. </i><br>
          | <a href="data/tang2021disentangled.bib">BibTeX</a> |
        </p>
        <p>
            A novel disentangled generative deep model for chest X-ray decomposition that can interpret chest X-rays by outputting disease residue or saliency maps, to improve radiology workflow and patient care.
        </p>
    </td>

</tr>
</tbody></table>

<!-- paul2021discriminative -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="cxr_fsl_stop()" onmouseover="cxr_fsl_start()">
    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="fsl_image" style="opacity: 0;">
                <img src="images/mia_cxr_fsl_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="fsl_constant" style="opacity: 1;">
                <img src="images/mia_cxr_fsl.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function cxr_fsl_start() {
                document.getElementById('fsl_constant').style.opacity = "0";
                document.getElementById('fsl_image').style.opacity = "1";
            }

            function cxr_fsl_stop() {
                document.getElementById('fsl_image').style.opacity = "0";
                document.getElementById('fsl_constant').style.opacity = "1";
            }
            cxr_fsl_stop()
        </script>
    </td>
    
    <td width="70%" valign="top">
        <p>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520302759?dgcid=rss_sd_all" id="tang2021disentangled">
                <heading>Discriminative ensemble learning for few-shot chest x-ray diagnosis</heading>
            </a><br>
            Angshuman Paul, <b>Yu-Xing Tang</b>, Thomas C. Shen, Ronald M. Summers<br>
            <i>Medical Image Analysis (<b>MedIA</b>), 2021. </i><br>
          | <a href="data/paul2021discriminative.bib">BibTeX</a> |
        </p>
        <p>
            A two-step solution for few-shot learning for disease classification in chest X-rays.
        </p>
    </td>

</tr>
</tbody></table>

<!-- peng2020covid -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="tbd_covid_stop()" onmouseover="tbd_covid_start()">
    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="covid_image" style="opacity: 0;">
                <img src="images/tbd_covid_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="covid_constant" style="opacity: 1;">
                <img src="images/tbd_covid.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function tbd_covid_start() {
                document.getElementById('covid_constant').style.opacity = "0";
                document.getElementById('covid_image').style.opacity = "1";
            }

            function tbd_covid_stop() {
                document.getElementById('covid_image').style.opacity = "0";
                document.getElementById('covid_constant').style.opacity = "1";
            }
            tbd_covid_stop()
        </script>
    </td>
    
    <td width="70%" valign="top">
        <p>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9248607" id="peng2020covid">
                <heading>COVID-19-CT-CXR: a freely accessible and weakly labeled chest X-ray and CT image collection on COVID-19 from biomedical literature</heading>
            </a><br>
            Yifan Peng, <b>Yu-Xing Tang</b>, Sungwon Lee, Yingying Zhu, Ronald M. Summers, Zhiyong Lu<br>
            <i>IEEE Transactions on Big Data (<b>TBD</b>), 2021. </i><br>
          | <a href="data/peng2020covid.bib">BibTeX</a> | <a href="https://github.com/ncbi-nlp/COVID-19-CT-CXR">Code and data</a> |
        </p>
        <p>
            We develop a framework for rapidly constructing a chest X-ray/CT database containing Covid-19 images from PubMed Central® (PMC) full-text articles.
        </p>
    </td>

</tr>
</tbody></table>

<!-- tang2020automated -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="cxr_npj_stop()" onmouseover="cxr_npj_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="resim_image" style="opacity: 0;">
                <img src="images/npj-DM-CXR-1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="resim_constant" style="opacity: 1;">
                <img src="images/npj-DM-CXR.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function cxr_npj_start() {
                document.getElementById('resim_constant').style.opacity = "0";
                document.getElementById('resim_image').style.opacity = "1";
            }

            function cxr_npj_stop() {
                document.getElementById('resim_image').style.opacity = "0";
                document.getElementById('resim_constant').style.opacity = "1";
            }
            cxr_npj_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://www.nature.com/articles/s41746-020-0273-z" id="tang2020automated">
                <heading>Automated abnormality classification of chest radiographs using deep convolutional neural networks</heading>
            </a><br>
            <b>Yu-Xing Tang</b>, You-Bao Tang, Yifan Peng, Ke Yan, Mohammadhadi Bagheri, Bernadette A. Redd, Catherine J. Brandon, Zhiyong Lu, Mei Han, Jing Xiao, Ronald M. Summers<br>
            <i>npj Digital Medicine, Nature Publishing Group, 2020. </i><br>
          | <a href="data/tang2020automated.bib">BibTeX</a> 
          | <a href="https://github.com/rsummers11/CADLab/tree/master/CXR-Binary-Classifier">Code</a> | <a href="https://nihcc.box.com/s/tiniov0agwsewzd243dxrt9mqa271pat">Model</a> 
          | <a href="https://nihcc.app.box.com/v/ChestXray-NIHCC">Data</a> | <a href="https://www.auntminnie.com/index.aspx?sec=ser&sub=def&pag=dis&ItemID=129039">Media</a> |
        </p>
        <p>
            AI algorithms can distinguish normal and abnormal chest X-rays with accuracy comparable to that of experienced radiologists, allowing these studies to be triaged for priority review.
        </p>
    </td>

</tr>
</tbody></table>

<!-- yan2020learning -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="yan_tmi_stop()" onmouseover="yan_tmi_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="yan_tmi_res_image" style="opacity: 0;">
                <img src="images/yan_tmi_ct_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="yan_tmi_image" style="opacity: 1;">
                <img src="images/yan_tmi_ct.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function yan_tmi_start() {
                document.getElementById('yan_tmi_image').style.opacity = "0";
                document.getElementById('yan_tmi_res_image').style.opacity = "1";
            }

            function yan_tmi_stop() {
                document.getElementById('yan_tmi_res_image').style.opacity = "0";
                document.getElementById('yan_tmi_image').style.opacity = "1";
            }
            yan_tmi_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://ieeexplore.ieee.org/abstract/document/9309244" id="yan2020learning">
                <heading>Learning from multiple datasets with heterogeneous and partial labels for universal lesion detection in CT</heading>
            </a><br>
            Ke Yan, Jinzheng Cai, Youjing Zheng, Adam P. Harrison, Dakai Jin, Youbao Tang, <b>Yuxing Tang</b>, Lingyun Huang, Jing Xiao, Le Lu<br>
            <i>IEEE Transactions on Medical Imaging (<b>TMI</b>), 2020. </i><br>
          | <a href="data/yan2020learning.bib">BibTeX</a> | <a href="https://arxiv.org/pdf/2009.02577.pdf">arXiv</a> | <a href="https://github.com/viggin/DeepLesion_manual_test_set">Data</a> |
        </p>
        <p>
            LENS (Lesion ENSemble) is a universal lesion detection framework that can effectively learn with multiple heterogeneous datasets and mine missing annotations from partially-labeled datasets.
    </td>

</tr>
</tbody></table>

<!-- tang2018visual -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="tang_pami18_stop()" onmouseover="tang_pami18_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="tang_pami18_res_image" style="opacity: 0;">
                <img src="images/tang_pami18_res.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="tang_pami18_image" style="opacity: 1;">
                <img src="images/tang_pami18.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function tang_pami18_start() {
                document.getElementById('tang_pami18_image').style.opacity = "0";
                document.getElementById('tang_pami18_res_image').style.opacity = "1";
            }

            function tang_pami18_stop() {
                document.getElementById('tang_pami18_res_image').style.opacity = "0";
                document.getElementById('tang_pami18_image').style.opacity = "1";
            }
            tang_pami18_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://ieeexplore.ieee.org/document/8103045" id="tang2018visual">
                <heading>Visual and semantic knowledge transfer for large scale semi-supervised object detection</heading>
            </a><br>
            <b>Yuxing Tang</b>, Josiah Wang, Xiaofang Wang, Boyang Gao, Emmanuel Dellandrea, Robert Gaizauskas, Liming Chen<br>
            <i>IEEE Transactions on Pattern Analysis and Machine Intelligence  (<b>TPAMI</b>), 2018. </i><br>
          | <a href="data/tang2018visual.bib">BibTeX</a> | <a href="https://arxiv.org/pdf/1801.03145.pdf">arXiv</a> |
        </p>
        <p>
            Can knowledge about visual and semantic similarities of object categories help improve the performance of detectors trained in a semi- or weakly- supervised setting?
    </td>

</tr>
</tbody></table>

<!-- tang2017weakly -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="tmm_dpm_stop()" onmouseover="tmm_dpm_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="tmm_dpm_res_image" style="opacity: 0;">
                <img src="images/tmm_dpm_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="tmm_dpm_image" style="opacity: 1;">
                <img src="images/tmm_dpm.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function tmm_dpm_start() {
                document.getElementById('tmm_dpm_image').style.opacity = "0";
                document.getElementById('tmm_dpm_res_image').style.opacity = "1";
            }

            function tmm_dpm_stop() {
                document.getElementById('tmm_dpm_res_image').style.opacity = "0";
                document.getElementById('tmm_dpm_image').style.opacity = "1";
            }
            tmm_dpm_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://ieeexplore.ieee.org/document/7581027" id="tang2017weakly">
                <heading>Weakly supervised learning of deformable part-based models for object detection via region proposals</heading>
            </a><br>
            <b>Yuxing Tang</b>, Xiaofang Wang, Emmanuel Dellandrea, Liming Chen<br>
            <i>IEEE Transactions on Multimedia (<b>TMM</b>), 2017. </i><br>
          | <a href="data/tang2017weakly.bib">BibTeX</a> | <a href="https://openreview.net/pdf?id=TMVALa8MjD">PDF</a> |
        </p>
        <p>
            Using region proposals to improve the weakly supervised deformable part-based model.
    </td>

</tr>
</tbody></table>

<!-- wang2015global -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="tip_seg_stop()" onmouseover="tip_seg_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="tip_res_image" style="opacity: 0;">
                <img src="images/tip_seg_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="tip_image" style="opacity: 1;">
                <img src="images/tip_seg.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function tip_seg_start() {
                document.getElementById('tip_image').style.opacity = "0";
                document.getElementById('tip_res_image').style.opacity = "1";
            }

            function tip_seg_stop() {
                document.getElementById('tip_res_image').style.opacity = "0";
                document.getElementById('tip_image').style.opacity = "1";
            }
            tip_seg_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://ieeexplore.ieee.org/document/7024152" id="wang2015global">
                <heading>A global/local affinity graph for image segmentation</heading>
            </a><br>
            Xiaofang Wang, <b>Yuxing Tang</b>, Simon Masnou, Liming Chen<br>
            <i>IEEE Transactions on Image Processing (<b>TIP</b>), 2015. </i><br>
          | <a href="data/wang2015global.bib">BibTeX</a> | <a href="https://www.researchgate.net/publication/271772745_A_GlobalLocal_Affinity_Graph_for_Image_Segmentation">PDF</a> | <a href="https://github.com/xiaofanglegoc/global-local-affinity-graph">Code</a> |
        </p>
        <p>
            A sparse global/local affinity graph over superpixels of an input image to capture both short and long range grouping cues.
    </td>

</tr>
</tbody></table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tbody><tr><td><heading>&nbsp;&nbsp;<p id="conf_pub"><li>Conferences</li></p></heading></td></tr></tbody>
</table>

<!-- tang2021leveraging -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="cvpr21_stop()" onmouseover="cvpr21_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="cvpr21_res_image" style="opacity: 0;">
                <img src="images/cvpr21_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="cvpr21_image" style="opacity: 1;">
                <img src="images/cvpr21.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function cvpr21_start() {
                document.getElementById('cvpr21_image').style.opacity = "0";
                document.getElementById('cvpr21_res_image').style.opacity = "1";
            }

            function cvpr21_stop() {
                document.getElementById('cvpr21_res_image').style.opacity = "0";
                document.getElementById('cvpr21_image').style.opacity = "1";
            }
            cvpr21_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Leveraging_Large-Scale_Weakly_Labeled_Data_for_Semi-Supervised_Mass_Detection_in_CVPR_2021_paper.pdf" id="tang2021leveraging">
                <heading>Leveraging large-scale weakly labeled data for semi-supervised mass detection in mammograms</heading>
            </a><br>
            <b>Yuxing Tang</b>, Zhenjie Cao, Yanbo Zhang, Zhicheng Yang, Zongcheng Ji, Yiwei Wang, Mei Han, Jie Ma, Jing Xiao, Peng Chang<br>
            <i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021. </i><br>
          | <a href="data/tang2021leveraging.bib">BibTeX</a> | <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Tang_Leveraging_Large-Scale_Weakly_CVPR_2021_supplemental.pdf">Supp</a> |
        </p>
        <p>
            A novel self-training framework for semi-supervised mass detection with soft image-level labels generated from diagnosis reports by a RoBERTa-based NLP model.
    </td>

</tr>
</tbody></table>

<!-- zhang2021birads -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr>
<!-- <tr onmouseout="maccai21_birads_stop()" onmouseover="maccai21_birads_start()">

     <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="maccai21_birads_res_image" style="opacity: 0;">
                <img src="images/.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="maccai21_birads_image" style="opacity: 1;">
                <img src="images/.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function maccai21_birads_start() {
                document.getElementById('maccai21_birads_image').style.opacity = "0";
                document.getElementById('maccai21_birads_res_image').style.opacity = "1";
            }

            function maccai21_birads_stop() {
                document.getElementById('maccai21_birads_res_image').style.opacity = "0";
                document.getElementById('maccai21_birads_image').style.opacity = "1";
            }
            maccai21_birads_stop()
        </script>
    </td> -->

    <td width="30%" valign="center" align="center">
        <img src="images/miccai21_birads.png" style="display: inline" width="100%">
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="pdfs/miccai21_birads.pdf" id="zhang2021birads">
                <heading>BI-RADS classification of calcification on mammograms</heading>
            </a><br>
            Yanbo Zhang, <b>Yuxing Tang</b>, Zhenjie Cao, Mei Han, Jing Xiao, Jie Ma, Peng Chang<br>
            <i>International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2021. </i><br>
          | <a href="data/zhang2021birads.bib">BibTeX</a> |
        </p>
        <p>
            A deep learning-based BI-RADS classification for individual calcification in mammograms. A new evaluation metric for BI-RADS classification which considers the severity of malignancy. 
    </td>

</tr>
</tbody></table>

<!-- cao2021contrastive -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>

    <tr>
    <td width="30%" valign="center" align="center">
        <img src="images/miccai21_contrastive.png" style="display: inline" width="100%">
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="pdfs/miccai21_contrastive.pdf" id="cao2021contrastive">
                <heading>Supervised contrastive pre-training for mammographic triage screening models</heading>
            </a><br>
            Zhenjie Cao, Zhicheng Yang, <b>Yuxing Tang</b>, Yanbo Zhang, Mei Han, Jing Xiao, Jie Ma, Peng Chang<br>
            <i>International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2021. </i><br>
          | <a href="data/cao2021contrastive.bib">BibTeX</a> |
        </p>
        <p>
            A framework of supervised contrastive pre-training followed by supervised fine-tuning to improve mammographic triage screening models.
    </td>

</tr>
</tbody></table>

<!-- tang2020net -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15"><tbody>
<tr onmouseout="miccai21_e2net_stop()" onmouseover="miccai21_e2net_start()">

    <td width="30%" valign="center" align="center">
        <div class="image_mouseout">
            <div class="image_mouseover" id="miccai21_e2net_res_image" style="opacity: 0;">
                <img src="images/miccai21_e2net_1.png" ,="" width="100%">
            </div>
            <div class="image_constant" id="miccai21_e2net_image" style="opacity: 1;">
                <img src="images/miccai21_e2net.png" ,="" width="100%">
            </div>
        </div>
        <script type="text/javascript">
            function miccai21_e2net_start() {
                document.getElementById('miccai21_e2net_image').style.opacity = "0";
                document.getElementById('miccai21_e2net_res_image').style.opacity = "1";
            }

            function miccai21_e2net_stop() {
                document.getElementById('miccai21_e2net_res_image').style.opacity = "0";
                document.getElementById('miccai21_e2net_image').style.opacity = "1";
            }
            miccai21_e2net_stop()
        </script>
    </td>

    <td width="70%" valign="top">
        <p>
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-59719-1_50" id="tang2020net">
                <heading>E&#178;Net: An edge enhanced network for accurate liver and tumor segmentation on CT scans</heading>
            </a><br>
            Youbao Tang, <b>Yuxing Tang</b>, Yingying Zhu, Jing Xiao, Ronald M. Summers<br>
            <i>International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2020. </i><br>
          | <a href="data/tang2020net.bib">BibTeX</a> | <a href="https://arxiv.org/pdf/2007.09791.pdf">arXiv</a> |
        </p>
        <p>
            A two-stage framework (edge enhanced network) for 2D liver and tumor segmentation on CT scans.
    </td>

</tr>
</tbody></table>

<!-- award -->

<table width="100%" align="center" border="0" cellpadding="10">
  <tbody><tr><td><sectionheading>&nbsp;&nbsp;Awards</sectionheading>
    <ul>
        <li><b>CVPR Outstanding Reviewer Award</b>, 2020</li>
        <li><b>RSNA Trainee Research Prize</b>, 2019</li>
        <li><b>ISBI Travel Award</b>, 2019</li>
        <li><b>IAPR Outstanding Reviewer Award</b>, 2018</li>
        <li><b>CVPR Doctoral Consortium Travel Grant</b>, 2016</li>
    </ul>
  </td></tr></tbody>
</table>

<!-- service -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
  <tbody><tr><td><sectionheading>&nbsp;&nbsp;Services</sectionheading>
  <tbody><tr><td><heading><li>&nbsp;&nbsp;Journal reviews</li></heading>
  <ul>
      <b>IEEE</b> TIP / TNNLS / TMI / TMM / TCSVT / JBHI / TBD / Access<br>
      <b>Elsevier</b> MedIA/ PR / PRL / NEUCOM<br>
      <b>Nature Publication Group</b> npj Digital Medicine / Scientific Reports<br>
      <b>RSNA</b> Radiology / Radiology: AI / Cardiothoracic Imaging<br>
      <b>IET</b> Computer Vision / Signal Processing / Image Processing / Electronics Letters<br>
      <b>MDPI</b>  Sensors / Remote Sensing /  Applied Sciences  / Algorithms <br>
      <b>SPIE</b> Journal of Electronic Imaging<br> 
        Medical Physics, PLOS ONE<br></a>
  </ul>
  <tbody><tr><td><heading><li>&nbsp;&nbsp;Conference reviews or technical/program committee</li></heading>
  <ul>
    CVPR 2018/2019/2020/2021, ICCV 2019, MICCAI 2018/2019, AAAI 2020, ECCV 2020, ACCV 2018, ICHI 2019, PRCV 2019<br> </a>
  </ul>
  </td></tr></tbody>
  </td></tr></tbody>
</table>

<!-- contact -->

<!-- <table width="100%" align="center" border="0" cellpadding="10">
  <tbody><tr><td><sectionheading>&nbsp;&nbsp;Contact</sectionheading>
        <p style="margin-left: 5%;">
        XXX
        </p>
  </td></tr></tbody>
</table> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody><tr><td><br>
    <p align="right"><font size="2">
        <b>Website design</b>: <a href="http://www.cs.berkeley.edu/~barron/">✩</a> <a href="https://tetexiao.com/">✩</a><br>
    </font></p>
</td></tr></tbody></table>
        
</td></tr></tbody></table>

</body></html>